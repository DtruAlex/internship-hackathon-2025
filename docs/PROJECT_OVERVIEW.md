# AI Code Review Assistant - Project Overview

## ğŸ¯ Project Summary

A powerful, local-first TUI application that provides intelligent AI-powered code reviews before you commit. Built for the Haufe 2025 Hackathon, this tool integrates seamlessly with your Git workflow to help catch bugs, improve code quality, and learn best practices.

## âœ¨ Key Features

- **ğŸ¤– AI-Powered Analysis**: Uses LLama 3.2:1B via Ollama for intelligent, context-aware code reviews
- **ğŸ¨ Beautiful TUI**: Rich terminal interface with syntax highlighting and intuitive navigation
- **âš¡ Fast & Local**: All processing happens on your machine - no data leaves your computer
- **ğŸ” Smart Git Integration**: Automatically detects and analyzes changes (staged/unstaged/untracked)
- **ğŸ“Š Detailed Feedback**: Get actionable suggestions on bugs, security, performance, and best practices
- **ğŸ”„ Parallel Processing**: Reviews multiple files simultaneously for speed
- **ğŸ¯ Customizable**: Easy configuration for prompts, models, and review criteria

## ğŸ“ Project Structure

```
haufe-2025-hackathon/
â”œâ”€â”€ main.py                 # Application entry point and orchestration
â”œâ”€â”€ code_reviewer.py        # Core review logic with parallel processing
â”œâ”€â”€ git_handler.py          # Git operations and file detection
â”œâ”€â”€ ollama_client.py        # Ollama API integration
â”œâ”€â”€ tui.py                 # Rich-based terminal user interface
â”œâ”€â”€ config.py              # Centralized configuration
â”œâ”€â”€ examples.py            # Testing and demonstration utilities
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ setup.sh              # Automated setup script
â”œâ”€â”€ run.sh                # Quick run wrapper
â”œâ”€â”€ test.sh               # Comprehensive test suite
â”œâ”€â”€ pre-commit-hook.sh    # Git pre-commit hook template
â”œâ”€â”€ README.md             # Main documentation
â”œâ”€â”€ QUICKSTART.md         # Quick start guide
â”œâ”€â”€ DEVELOPER_GUIDE.md    # Detailed developer documentation
â”œâ”€â”€ CONTRIBUTING.md       # Contribution guidelines
â””â”€â”€ LICENSE               # MIT License
```

## ğŸš€ Quick Start

```bash
# 1. Setup (one time)
./setup.sh

# 2. Start Ollama (in separate terminal)
ollama serve

# 3. Run the app
./run.sh --interactive
```

## ğŸ› ï¸ Technology Stack

- **Python 3.8+**: Core language
- **Rich**: Beautiful TUI components
- **GitPython**: Git repository interaction
- **Ollama**: Local LLM inference
- **LLama 3.2:1B**: AI model for code review
- **ThreadPoolExecutor**: Parallel review processing

## ğŸ“Š Architecture

```
User
  â†“
main.py (CodeReviewApp)
  â†“
â”œâ”€â†’ tui.py (ReviewTUI)           # User interface
â”œâ”€â†’ code_reviewer.py              # Review orchestration
â”‚   â”œâ”€â†’ ollama_client.py         # AI communication
â”‚   â””â”€â†’ git_handler.py           # Git operations
â””â”€â†’ config.py                     # Configuration
```

## ğŸ“ Use Cases

1. **Pre-Commit Reviews**: Catch issues before they enter version control
2. **Learning Tool**: Get instant feedback on your code to improve skills
3. **Team Standards**: Ensure code follows best practices
4. **Security Scanning**: Identify potential security vulnerabilities
5. **Code Quality**: Maintain high standards across your codebase

## ğŸ”§ Configuration

All settings in `config.py`:

- **Model Selection**: Choose different Ollama models
- **Review Criteria**: Customize what to check
- **Batch Size**: Adjust parallel processing
- **Prompts**: Tailor AI behavior
- **Exclusions**: Skip certain files

## ğŸ“ˆ Performance

- **Speed**: ~2-5 seconds per file (depending on model and file size)
- **Parallel Processing**: Reviews up to 5 files simultaneously
- **Resource Efficient**: LLama 3.2:1B requires minimal resources
- **Smart Truncation**: Handles large files gracefully

## ğŸ§ª Testing

```bash
# Run all tests
./test.sh

# Test specific components
python examples.py test-ollama   # Test AI connection
python examples.py test-git      # Test Git integration
python examples.py demo          # Demo UI components
```

## ğŸ”’ Privacy & Security

- **100% Local**: No data sent to external servers
- **Open Source**: Fully transparent code
- **Your Control**: You own and control all data
- **No Tracking**: No analytics or telemetry

## ğŸ¯ Future Enhancements

Potential additions:
- [ ] Export reviews to JSON/HTML/PDF
- [ ] Integration with GitHub/GitLab APIs
- [ ] Automated fix suggestions
- [ ] Historical review tracking
- [ ] VS Code/JetBrains plugins
- [ ] Multi-model comparison
- [ ] Team collaboration features
- [ ] Custom rule engines
- [ ] CI/CD integration
- [ ] Web dashboard

## ğŸ¤ Contributing

Contributions are welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Haufe 2025 Hackathon for the opportunity
- Ollama team for the amazing local LLM platform
- Meta for the LLama models
- Rich library for beautiful terminal UI
- GitPython for seamless Git integration

## ğŸ“ Support

- Check [QUICKSTART.md](QUICKSTART.md) for setup help
- See [DEVELOPER_GUIDE.md](DEVELOPER_GUIDE.md) for detailed docs
- Run `./test.sh` to diagnose issues
- Open an issue for bug reports

## ğŸ‰ Getting Started

Ready to transform your code review process?

```bash
./setup.sh
./run.sh --interactive
```

Happy coding! ğŸš€

---

**Built with â¤ï¸ for the Haufe 2025 Hackathon**

